# flan-t5-small: Prompt Evolution System

**Purpose**: Meta-learning system that continuously improves tinyArms prompts through user feedback
**Status**: Research phase (0% implemented)
**Date**: 2025-10-27

---

## Core Concept

**NOT a per-task optimizer** (that would add 500ms to every operation)

**IS a meta-learning system** that:
1. Generates prompt variants when accuracy drops
2. A/B tests variants with users
3. Learns from user choices
4. Evolves prompts over time

---

## How It Works

### Trigger: Accuracy Drop Detected

```yaml
# config/constants.yaml
prompt_evolution:
  trigger:
    skill_accuracy_threshold: 0.80  # Below 80% = trigger evolution
    feedback_sample_size: 20        # Need 20 samples to detect drop
    evolution_cooldown_hours: 168   # Max once per week per skill
```

**Example**:
```
file-naming skill accuracy: 92% → 78% (dropped 14%)
Trigger: Generate new prompt variants
```

---

### Step 1: flan-t5 Generates Variants

**Input to flan-t5**:
```
Current prompt: "Rename this file based on its visual content. Be descriptive and use kebab-case."

Recent failures:
- Screenshot 2024.png → "untitled-1.png" (BAD: not descriptive)
- IMG_5678.jpg → "image-file.jpg" (BAD: generic)
- mockup-final-v2.png → "design-mockup.png" (GOOD but lost version info)

Task: Generate 3 alternative prompts that improve accuracy.
```

**flan-t5 output** (3 variants):
```yaml
variant_a:
  prompt: "Analyze the image content and rename with descriptive keywords. Format: [main-subject]-[context]-[type].kebab-case. Examples: hero-section-mobile-mockup.png, user-profile-wireframe-v3.png"
  reasoning: "Adds structured format with examples"

variant_b:
  prompt: "Describe what you see in the image as a filename. Include: main objects, colors if distinctive, purpose/context. Use 3-5 words maximum, kebab-case."
  reasoning: "Limits verbosity, adds color context"

variant_c:
  prompt: "Rename based on visual analysis. Priority: 1) Main subject/purpose, 2) Platform (mobile/desktop), 3) Version if visible. Format: subject-platform-version.extension"
  reasoning: "Prioritizes key metadata extraction"
```

---

### Step 2: A/B Test with Users

**When next file needs naming**:

```
┌─────────────────────────────────────────────────────────────┐
│ 🦖 tinyArms: File Naming - Help Us Improve!                │
├─────────────────────────────────────────────────────────────┤
│ File: Screenshot-2024-10-27.png                            │
│                                                             │
│ We're testing new prompts. Choose your preferred name:     │
│                                                             │
│ Option A: hero-section-mobile-mockup.png                   │
│   (Generated by: Variant A - Structured format)            │
│                                                             │
│ Option B: website-header-blue-accent.png                   │
│   (Generated by: Variant B - Color context)                │
│                                                             │
│ Option C: hero-mobile-v1.png                               │
│   (Generated by: Variant C - Prioritized metadata)         │
│                                                             │
│ [A] [B] [C] [Skip and use current prompt]                  │
└─────────────────────────────────────────────────────────────┘
```

---

### Step 3: Learn from Choices

**Track results**:
```yaml
# SQLite: prompt_evolution table
evolution_session_id: abc123
skill: file-naming
original_prompt_hash: def456
variants:
  - id: variant_a
    prompt: "Analyze the image..."
    votes: 12
    accuracy: 0.87

  - id: variant_b
    prompt: "Describe what you see..."
    votes: 8
    accuracy: 0.82

  - id: variant_c
    prompt: "Rename based on visual..."
    votes: 15  # Winner!
    accuracy: 0.91

winning_variant: variant_c
promoted_at: "2024-11-03T10:00:00Z"
```

**After 30 votes** (or 7 days):
- Variant C wins (15 votes, 91% accuracy)
- Update skill config:

```yaml
# config.yaml - Updated automatically
skills:
  file-naming:
    prompt_template: skills/file-naming-v2.md  # ← Updated!
    prompt_version: 2
    evolved_at: "2024-11-03T10:00:00Z"
    previous_accuracy: 0.78
    current_accuracy: 0.91
```

---

## Architecture

```
┌─────────────────────────────────────────────────────────────┐
│                    Accuracy Monitor                         │
│  (Background service, checks every 24 hours)                │
│                                                             │
│  Query SQLite: SELECT accuracy FROM task_history           │
│  WHERE skill = 'file-naming'                                │
│  AND created_at > NOW() - INTERVAL 7 DAYS                   │
│  GROUP BY skill                                             │
│                                                             │
│  IF accuracy < 0.80 AND last_evolution > 7 days ago:        │
│    TRIGGER: Prompt Evolution                                │
└─────────────────────────────────────────────────────────────┘
                          ↓
┌─────────────────────────────────────────────────────────────┐
│              flan-t5-small Prompt Generator                 │
│  (Runs ONCE when triggered, not per-task)                  │
│                                                             │
│  Input:                                                     │
│    - Current prompt                                         │
│    - Recent failure examples (20 samples)                   │
│    - Successful examples (top 10)                           │
│    - Skill context (file naming, code linting, etc.)       │
│                                                             │
│  Output:                                                    │
│    - 3 prompt variants with reasoning                       │
│                                                             │
│  Latency: ~2-3s (one-time cost)                            │
└─────────────────────────────────────────────────────────────┘
                          ↓
┌─────────────────────────────────────────────────────────────┐
│                   A/B Testing Phase                         │
│  (Next 30 tasks for this skill)                            │
│                                                             │
│  For each task:                                             │
│    1. Run all 4 prompts (original + 3 variants)            │
│    2. Show user 3 results (random order)                    │
│    3. User picks best                                       │
│    4. Record: variant_id, user_choice, task_success         │
│                                                             │
│  After 30 votes or 7 days:                                  │
│    - Calculate winner (votes × accuracy)                    │
│    - Promote winning prompt to production                   │
│    - Archive other variants                                 │
└─────────────────────────────────────────────────────────────┘
                          ↓
┌─────────────────────────────────────────────────────────────┐
│                   Promotion & Learning                      │
│                                                             │
│  1. Update skill config with winning prompt                 │
│  2. Log evolution history (for rollback)                    │
│  3. Reset accuracy counter                                  │
│  4. Continue monitoring...                                  │
└─────────────────────────────────────────────────────────────┘
```

---

## User Experience

### Silent Evolution (Default)

**Week 1-6**: Skill works normally at 92% accuracy
**Week 7**: Accuracy drops to 78%
**Week 8**: tinyArms detects drop, generates variants (user sees nothing yet)
**Week 8-9**: User occasionally sees A/B choice dialogs (10-30 times)
**Week 10**: Winning prompt auto-promoted, accuracy back to 90%

**User never had to edit YAML or write prompts manually**

---

### Power User Mode (Optional)

```bash
# View current prompt performance
tinyarms prompt stats file-naming

# Output:
# Skill: file-naming
# Current accuracy: 78% (down from 92%)
# Prompt version: 1 (active since 2024-09-15)
# Recent failures: 15/70 tasks (21%)
# Status: Evolution triggered, A/B testing in progress

# Force prompt evolution (skip waiting for drop)
tinyarms prompt evolve file-naming --variants 5

# Output:
# Generating 5 prompt variants with flan-t5...
# Variants saved. Next 50 tasks will A/B test.

# View A/B test results
tinyarms prompt results file-naming

# Output:
# Evolution Session: abc123
# Variant A: 12 votes, 87% accuracy
# Variant B: 8 votes, 82% accuracy
# Variant C: 15 votes, 91% accuracy ← WINNING
# 5 tasks remaining in test period

# Manually promote a variant
tinyarms prompt promote file-naming variant_c
```

---

## Configuration

```yaml
# config/constants.yaml

prompt_evolution:
  enabled: true

  triggers:
    accuracy_threshold: 0.80        # ESTIMATED - Industry "good enough" bar
    # Source: ML ops standard (80% = acceptable, 90% = excellent)
    # Status: PLACEHOLDER - tune based on user tolerance

    sample_size: 20                 # ARBITRARY - Need statistical significance
    # Source: NONE (gut feeling: 20 samples = reasonable)
    # Status: PLACEHOLDER - may need 50+ for confidence

    cooldown_hours: 168             # ARBITRARY - Once per week max
    # Source: NONE (prevent evolution fatigue)
    # Status: PLACEHOLDER - tune based on user feedback

  ab_testing:
    votes_required: 30              # ARBITRARY - Enough for winner
    # Source: A/B testing best practices (30+ samples = significance)
    # Status: PLACEHOLDER - may be too many

    max_duration_days: 7            # ARBITRARY - Force decision after 1 week
    # Source: NONE (don't test forever)
    # Status: PLACEHOLDER

    show_probability: 0.5           # ARBITRARY - 50% of tasks show A/B choice
    # Source: Balance learning vs annoyance
    # Status: PLACEHOLDER - tune based on user feedback

  flan_t5:
    model: "flan-t5:small"
    variants_per_evolution: 3       # ARBITRARY - Too many = choice paralysis
    # Source: UX research (3-4 options = optimal choice)
    # Status: PLACEHOLDER

    latency_budget_ms: 5000         # ESTIMATED - Acceptable for one-time cost
    # Source: Evolution is async, user doesn't wait
    # Status: NEEDS_VALIDATION

  learning:
    min_accuracy_improvement: 0.05  # ARBITRARY - 5% = meaningful
    # Source: NONE (5% seems worth the effort)
    # Status: PLACEHOLDER

    rollback_threshold: 0.70        # ARBITRARY - If new prompt < 70%, rollback
    # Source: Safety net (don't make things worse)
    # Status: PLACEHOLDER
```

---

## Skills That Benefit

### High Variation Skills (Good Candidates)

**file-naming**:
- High variation in image content (screenshots, photos, diagrams)
- User preferences vary (some want verbose, some concise)
- Hard to write perfect prompt upfront

**audio-actions**:
- Voice transcription quality varies (accents, background noise)
- Action extraction is subjective (what counts as "action"?)
- Prompts need tuning per user

**markdown-analysis**:
- Documentation style varies per project
- "Important change" is subjective
- Prompt evolves with project maturity

---

### Low Variation Skills (Poor Candidates)

**code-linting-fast**:
- Constitutional rules are fixed (hardcoded colors = always bad)
- Little room for prompt improvement (rules are rules)
- Accuracy issues = need better model, not better prompt

---

## Example: Image File Naming Evolution

### Initial Prompt (v1)

```markdown
# skills/file-naming.md (v1)

You are renaming a file based on its visual content.

Analyze the image and generate a descriptive filename using kebab-case.

Be concise but specific.
```

**Accuracy**: 92% (Weeks 1-6)

---

### Accuracy Drop (Week 7)

**Failures**:
- Screenshot-2024.png → "untitled-screen.png" (too generic)
- IMG_4521.jpg → "photo-landscape.jpg" (missed: "golden-gate-bridge")
- dashboard-final-v2.png → "ui-dashboard.png" (lost version number)

**Root cause analysis**:
- No structure guidance (too vague)
- No examples (model guesses format)
- No priority guidance (misses key details)

---

### flan-t5 Generates Variants (Week 8)

**Variant A** (Structured Format):
```markdown
Analyze the image and rename using this structure:
[main-subject]-[context]-[type].extension

Examples:
- golden-gate-bridge-sunset-photo.jpg
- dashboard-mobile-wireframe-v3.png
- hero-section-desktop-mockup.png

Format: kebab-case, 3-5 words
```

**Variant B** (Color Context):
```markdown
Describe the image as a filename. Include:
1. Main subject/objects
2. Distinctive colors (if notable)
3. Purpose/context

Format: subject-color-context.extension
Max 5 words, kebab-case

Examples:
- blue-button-component-hover.png
- red-alert-modal-mobile.png
```

**Variant C** (Prioritized Metadata):
```markdown
Rename based on visual analysis.

Priority order:
1. Main subject/purpose (required)
2. Platform (mobile/desktop/tablet)
3. Version number (if visible in filename or image)
4. State (hover, active, error, etc.)

Format: subject-platform-version-state.extension
Use kebab-case, omit unavailable fields

Examples:
- login-form-mobile-v2.png
- error-modal-desktop-active.png
- product-card-tablet.png
```

---

### A/B Testing Results (Week 8-9)

```
File: Screenshot-2024-10-28.png (landing page hero section on iPhone)

Variant A output: "hero-section-mobile-landing.png"
Variant B output: "blue-hero-mobile-header.png"
Variant C output: "hero-mobile-landing-v1.png"

User choice: Variant A (clear, no redundant "v1")

---

File: dashboard_FINAL_v3.png

Variant A output: "dashboard-admin-interface-v3.png"
Variant B output: "gray-dashboard-layout.png"
Variant C output: "dashboard-desktop-v3.png"

User choice: Variant C (captured version number!)

---

After 30 votes:
Variant A: 10 votes (33%)
Variant B: 5 votes (17%)
Variant C: 15 votes (50%) ← WINNER

Variant C accuracy: 91% (up from 78%)
```

---

### Promotion (Week 10)

```yaml
# config.yaml - Auto-updated
skills:
  file-naming:
    prompt_template: skills/file-naming-v2.md  # ← New version
    prompt_version: 2
    evolved_at: "2024-11-10T08:00:00Z"
    evolution_history:
      - version: 1
        active_period: "2024-09-15 to 2024-11-10"
        accuracy: 0.78
        reason: "Accuracy drop"
      - version: 2
        active_since: "2024-11-10"
        accuracy: 0.91
        source: "flan-t5 evolution (variant C)"
```

**New prompt file created**:
```bash
skills/file-naming-v2.md  # Variant C promoted
```

**Monitoring continues**: If v2 accuracy drops, trigger evolution again

---

## Implementation Phases

### Phase 1: Manual Prompt Evolution (No flan-t5)

```bash
# User manually creates variants
tinyarms prompt create file-naming \
  --variant-a skills/file-naming-structured.md \
  --variant-b skills/file-naming-colors.md \
  --variant-c skills/file-naming-priority.md

# tinyArms A/B tests (30 votes)
# Winner auto-promoted
```

**Deliverable**: A/B testing framework, winner promotion logic

---

### Phase 2: flan-t5 Auto-Generation

```bash
# Accuracy drops, flan-t5 auto-generates variants
# (No user action needed)
```

**Deliverable**: Integrate flan-t5:small, variant generation logic

---

### Phase 3: Multi-Skill Learning

```yaml
# Learnings from file-naming evolution applied to audio-actions
prompt_evolution:
  cross_skill_learning: true
  # If file-naming improved with "prioritized metadata" structure,
  # apply similar structure to audio-actions prompts
```

**Deliverable**: Meta-learning across skills

---

## Storage Schema

```sql
-- SQLite tables

CREATE TABLE prompt_evolution_sessions (
  id TEXT PRIMARY KEY,
  skill TEXT NOT NULL,
  original_prompt_hash TEXT NOT NULL,
  triggered_at TIMESTAMP NOT NULL,
  trigger_reason TEXT,  -- "accuracy_drop", "manual", "scheduled"
  status TEXT DEFAULT 'active',  -- active, completed, cancelled
  completed_at TIMESTAMP
);

CREATE TABLE prompt_variants (
  id TEXT PRIMARY KEY,
  session_id TEXT REFERENCES prompt_evolution_sessions(id),
  variant_letter TEXT,  -- A, B, C
  prompt_template TEXT NOT NULL,
  reasoning TEXT,  -- Why flan-t5 generated this variant
  votes INTEGER DEFAULT 0,
  accuracy REAL DEFAULT 0.0
);

CREATE TABLE ab_test_results (
  id TEXT PRIMARY KEY,
  session_id TEXT REFERENCES prompt_evolution_sessions(id),
  variant_id TEXT REFERENCES prompt_variants(id),
  task_id TEXT NOT NULL,
  user_choice BOOLEAN,  -- TRUE if user picked this variant
  task_success BOOLEAN,  -- TRUE if task completed successfully
  created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

CREATE TABLE prompt_history (
  id TEXT PRIMARY KEY,
  skill TEXT NOT NULL,
  version INTEGER NOT NULL,
  prompt_template_path TEXT NOT NULL,
  active_from TIMESTAMP NOT NULL,
  active_to TIMESTAMP,
  accuracy_start REAL,
  accuracy_end REAL,
  evolution_source TEXT,  -- "flan-t5", "manual", "initial"
  notes TEXT
);
```

---

## Cost Analysis

**Per evolution cycle**:
- flan-t5 inference: ~2-3s (one-time)
- A/B testing: 30 user choices (spread over 7 days)
- Storage: ~5KB per evolution session

**ROI**:
- Accuracy improvement: 5-15%
- User time saved: 2-3 hours/week (fewer manual prompt tweaks)
- Model swap avoidance: If prompt evolution fixes accuracy, no need to upgrade to larger model

**Break-even**: 1 evolution cycle = worth it if saves >1 hour of manual prompt engineering

---

## Testing Plan

### Phase 1: Manual Testing

1. Create 3 manual variants for file-naming
2. Run A/B test with 30 real files
3. Measure:
   - User choice distribution
   - Accuracy improvement
   - User satisfaction (survey)

**Success criteria**: Winner accuracy >85% (up from 78%)

---

### Phase 2: flan-t5 Testing

1. Use flan-t5 to generate variants (same failure examples)
2. Compare flan-t5 variants vs manual variants
3. Measure:
   - Variant quality (do they make sense?)
   - User choice distribution
   - Accuracy improvement

**Success criteria**: flan-t5 variants perform ≥ manual variants

---

### Phase 3: Production Testing

1. Deploy to 1 skill (file-naming)
2. Monitor for 1 month
3. Measure:
   - Number of evolution cycles triggered
   - Average accuracy improvement
   - User annoyance (A/B dialog frequency)

**Success criteria**: 2-3 evolution cycles, accuracy stable >85%, <10% users complain

---

## Risks & Mitigations

### Risk 1: Evolution Fatigue

**Problem**: Users annoyed by frequent A/B choice dialogs

**Mitigation**:
- Cooldown: Max 1 evolution per skill per week
- Sampling: Only 50% of tasks show A/B choice
- Skip button: Always allow using current prompt

---

### Risk 2: flan-t5 Generates Bad Variants

**Problem**: Variants are nonsensical or redundant

**Mitigation**:
- Manual review: Flag for human review if accuracy <70%
- Rollback: Auto-rollback to previous prompt if new prompt performs worse
- Diversity check: Reject variants too similar to original

---

### Risk 3: Overfitting to User

**Problem**: Prompts optimize for one user's preferences, not general use

**Mitigation**:
- Multi-user data: Aggregate votes from multiple users
- Canonical examples: Include gold-standard examples in evaluation
- Periodic reset: Option to reset to default prompt if user wants

---

## References

- **flan-t5 model card**: https://huggingface.co/google/flan-t5-small
- **A/B testing best practices**: Kohavi & Longbotham (2017), "Online Controlled Experiments"
- **Prompt optimization**: OpenAI prompt engineering guide
- **Meta-learning**: Nichol et al. (2018), "Reptile: A Scalable Meta-Learning Algorithm"

---

## Status

**Phase**: Research (0% implemented)
**Next steps**:
1. Validate flan-t5:small can generate coherent prompt variants
2. Build A/B testing UI (terminal prompt or macOS notification)
3. Implement SQLite schema for tracking
4. Test with file-naming skill (high variation, easy to judge)

**Timeline**:
- Phase 1 (Manual): Week 1-2 (build A/B framework)
- Phase 2 (flan-t5): Week 3-4 (integrate model)
- Phase 3 (Production): Week 5+ (deploy to 1-2 skills)

---

**Key insight**: flan-t5 is NOT a per-task overhead. It's a **self-improvement system** that runs in the background when skills need tuning.
