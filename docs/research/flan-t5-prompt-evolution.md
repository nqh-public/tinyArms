# flan-t5-small: Prompt Evolution System

**Purpose**: Meta-learning system that continuously improves tinyArms prompts through user feedback
**Status**: Research phase (0% implemented)
**Date**: 2025-10-27

---

## Core Concept

**NOT a per-task optimizer** (that would add 500ms to every operation)

**IS a meta-learning system** that:
1. Generates prompt variants when accuracy drops
2. A/B tests variants with users
3. Learns from user choices
4. Evolves prompts over time

---

## How It Works

### Trigger: Accuracy Drop Detected

```yaml
# config/constants.yaml
prompt_evolution:
  trigger:
    skill_accuracy_threshold: 0.80  # Below 80% = trigger evolution
    feedback_sample_size: 20        # Need 20 samples to detect drop
    evolution_cooldown_hours: 168   # Max once per week per skill
```

**Example**:
```
file-naming skill accuracy: 92% â†’ 78% (dropped 14%)
Trigger: Generate new prompt variants
```

---

### Step 1: flan-t5 Generates Variants

**Input to flan-t5**:
```
Current prompt: "Rename this file based on its visual content. Be descriptive and use kebab-case."

Recent failures:
- Screenshot 2024.png â†’ "untitled-1.png" (BAD: not descriptive)
- IMG_5678.jpg â†’ "image-file.jpg" (BAD: generic)
- mockup-final-v2.png â†’ "design-mockup.png" (GOOD but lost version info)

Task: Generate 3 alternative prompts that improve accuracy.
```

**flan-t5 output** (3 variants):
```yaml
variant_a:
  prompt: "Analyze the image content and rename with descriptive keywords. Format: [main-subject]-[context]-[type].kebab-case. Examples: hero-section-mobile-mockup.png, user-profile-wireframe-v3.png"
  reasoning: "Adds structured format with examples"

variant_b:
  prompt: "Describe what you see in the image as a filename. Include: main objects, colors if distinctive, purpose/context. Use 3-5 words maximum, kebab-case."
  reasoning: "Limits verbosity, adds color context"

variant_c:
  prompt: "Rename based on visual analysis. Priority: 1) Main subject/purpose, 2) Platform (mobile/desktop), 3) Version if visible. Format: subject-platform-version.extension"
  reasoning: "Prioritizes key metadata extraction"
```

---

### Step 2: A/B Test with Users

**When next file needs naming**:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ğŸ¦– tinyArms: File Naming - Help Us Improve!                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ File: Screenshot-2024-10-27.png                            â”‚
â”‚                                                             â”‚
â”‚ We're testing new prompts. Choose your preferred name:     â”‚
â”‚                                                             â”‚
â”‚ Option A: hero-section-mobile-mockup.png                   â”‚
â”‚   (Generated by: Variant A - Structured format)            â”‚
â”‚                                                             â”‚
â”‚ Option B: website-header-blue-accent.png                   â”‚
â”‚   (Generated by: Variant B - Color context)                â”‚
â”‚                                                             â”‚
â”‚ Option C: hero-mobile-v1.png                               â”‚
â”‚   (Generated by: Variant C - Prioritized metadata)         â”‚
â”‚                                                             â”‚
â”‚ [A] [B] [C] [Skip and use current prompt]                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### Step 3: Learn from Choices

**Track results**:
```yaml
# SQLite: prompt_evolution table
evolution_session_id: abc123
skill: file-naming
original_prompt_hash: def456
variants:
  - id: variant_a
    prompt: "Analyze the image..."
    votes: 12
    accuracy: 0.87

  - id: variant_b
    prompt: "Describe what you see..."
    votes: 8
    accuracy: 0.82

  - id: variant_c
    prompt: "Rename based on visual..."
    votes: 15  # Winner!
    accuracy: 0.91

winning_variant: variant_c
promoted_at: "2024-11-03T10:00:00Z"
```

**After 30 votes** (or 7 days):
- Variant C wins (15 votes, 91% accuracy)
- Update skill config:

```yaml
# config.yaml - Updated automatically
skills:
  file-naming:
    prompt_template: skills/file-naming-v2.md  # â† Updated!
    prompt_version: 2
    evolved_at: "2024-11-03T10:00:00Z"
    previous_accuracy: 0.78
    current_accuracy: 0.91
```

---

## Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Accuracy Monitor                         â”‚
â”‚  (Background service, checks every 24 hours)                â”‚
â”‚                                                             â”‚
â”‚  Query SQLite: SELECT accuracy FROM task_history           â”‚
â”‚  WHERE skill = 'file-naming'                                â”‚
â”‚  AND created_at > NOW() - INTERVAL 7 DAYS                   â”‚
â”‚  GROUP BY skill                                             â”‚
â”‚                                                             â”‚
â”‚  IF accuracy < 0.80 AND last_evolution > 7 days ago:        â”‚
â”‚    TRIGGER: Prompt Evolution                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              flan-t5-small Prompt Generator                 â”‚
â”‚  (Runs ONCE when triggered, not per-task)                  â”‚
â”‚                                                             â”‚
â”‚  Input:                                                     â”‚
â”‚    - Current prompt                                         â”‚
â”‚    - Recent failure examples (20 samples)                   â”‚
â”‚    - Successful examples (top 10)                           â”‚
â”‚    - Skill context (file naming, code linting, etc.)       â”‚
â”‚                                                             â”‚
â”‚  Output:                                                    â”‚
â”‚    - 3 prompt variants with reasoning                       â”‚
â”‚                                                             â”‚
â”‚  Latency: ~2-3s (one-time cost)                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   A/B Testing Phase                         â”‚
â”‚  (Next 30 tasks for this skill)                            â”‚
â”‚                                                             â”‚
â”‚  For each task:                                             â”‚
â”‚    1. Run all 4 prompts (original + 3 variants)            â”‚
â”‚    2. Show user 3 results (random order)                    â”‚
â”‚    3. User picks best                                       â”‚
â”‚    4. Record: variant_id, user_choice, task_success         â”‚
â”‚                                                             â”‚
â”‚  After 30 votes or 7 days:                                  â”‚
â”‚    - Calculate winner (votes Ã— accuracy)                    â”‚
â”‚    - Promote winning prompt to production                   â”‚
â”‚    - Archive other variants                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   Promotion & Learning                      â”‚
â”‚                                                             â”‚
â”‚  1. Update skill config with winning prompt                 â”‚
â”‚  2. Log evolution history (for rollback)                    â”‚
â”‚  3. Reset accuracy counter                                  â”‚
â”‚  4. Continue monitoring...                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## User Experience

### Silent Evolution (Default)

**Week 1-6**: Skill works normally at 92% accuracy
**Week 7**: Accuracy drops to 78%
**Week 8**: tinyArms detects drop, generates variants (user sees nothing yet)
**Week 8-9**: User occasionally sees A/B choice dialogs (10-30 times)
**Week 10**: Winning prompt auto-promoted, accuracy back to 90%

**User never had to edit YAML or write prompts manually**

---

### Power User Mode (Optional)

```bash
# View current prompt performance
tinyarms prompt stats file-naming

# Output:
# Skill: file-naming
# Current accuracy: 78% (down from 92%)
# Prompt version: 1 (active since 2024-09-15)
# Recent failures: 15/70 tasks (21%)
# Status: Evolution triggered, A/B testing in progress

# Force prompt evolution (skip waiting for drop)
tinyarms prompt evolve file-naming --variants 5

# Output:
# Generating 5 prompt variants with flan-t5...
# Variants saved. Next 50 tasks will A/B test.

# View A/B test results
tinyarms prompt results file-naming

# Output:
# Evolution Session: abc123
# Variant A: 12 votes, 87% accuracy
# Variant B: 8 votes, 82% accuracy
# Variant C: 15 votes, 91% accuracy â† WINNING
# 5 tasks remaining in test period

# Manually promote a variant
tinyarms prompt promote file-naming variant_c
```

---

## Configuration

```yaml
# config/constants.yaml

prompt_evolution:
  enabled: true

  triggers:
    accuracy_threshold: 0.80        # ESTIMATED - Industry "good enough" bar
    # Source: ML ops standard (80% = acceptable, 90% = excellent)
    # Status: PLACEHOLDER - tune based on user tolerance

    sample_size: 20                 # ARBITRARY - Need statistical significance
    # Source: NONE (gut feeling: 20 samples = reasonable)
    # Status: PLACEHOLDER - may need 50+ for confidence

    cooldown_hours: 168             # ARBITRARY - Once per week max
    # Source: NONE (prevent evolution fatigue)
    # Status: PLACEHOLDER - tune based on user feedback

  ab_testing:
    votes_required: 30              # ARBITRARY - Enough for winner
    # Source: A/B testing best practices (30+ samples = significance)
    # Status: PLACEHOLDER - may be too many

    max_duration_days: 7            # ARBITRARY - Force decision after 1 week
    # Source: NONE (don't test forever)
    # Status: PLACEHOLDER

    show_probability: 0.5           # ARBITRARY - 50% of tasks show A/B choice
    # Source: Balance learning vs annoyance
    # Status: PLACEHOLDER - tune based on user feedback

  flan_t5:
    model: "flan-t5:small"
    variants_per_evolution: 3       # ARBITRARY - Too many = choice paralysis
    # Source: UX research (3-4 options = optimal choice)
    # Status: PLACEHOLDER

    latency_budget_ms: 5000         # ESTIMATED - Acceptable for one-time cost
    # Source: Evolution is async, user doesn't wait
    # Status: NEEDS_VALIDATION

  learning:
    min_accuracy_improvement: 0.05  # ARBITRARY - 5% = meaningful
    # Source: NONE (5% seems worth the effort)
    # Status: PLACEHOLDER

    rollback_threshold: 0.70        # ARBITRARY - If new prompt < 70%, rollback
    # Source: Safety net (don't make things worse)
    # Status: PLACEHOLDER
```

---

## Skills That Benefit

### High Variation Skills (Good Candidates)

**file-naming**:
- High variation in image content (screenshots, photos, diagrams)
- User preferences vary (some want verbose, some concise)
- Hard to write perfect prompt upfront

**audio-actions**:
- Voice transcription quality varies (accents, background noise)
- Action extraction is subjective (what counts as "action"?)
- Prompts need tuning per user

**markdown-analysis**:
- Documentation style varies per project
- "Important change" is subjective
- Prompt evolves with project maturity

---

### Low Variation Skills (Poor Candidates)

**code-linting-fast**:
- Constitutional rules are fixed (hardcoded colors = always bad)
- Little room for prompt improvement (rules are rules)
- Accuracy issues = need better model, not better prompt

---

## Example: Image File Naming Evolution

### Initial Prompt (v1)

```markdown
# skills/file-naming.md (v1)

You are renaming a file based on its visual content.

Analyze the image and generate a descriptive filename using kebab-case.

Be concise but specific.
```

**Accuracy**: 92% (Weeks 1-6)

---

### Accuracy Drop (Week 7)

**Failures**:
- Screenshot-2024.png â†’ "untitled-screen.png" (too generic)
- IMG_4521.jpg â†’ "photo-landscape.jpg" (missed: "golden-gate-bridge")
- dashboard-final-v2.png â†’ "ui-dashboard.png" (lost version number)

**Root cause analysis**:
- No structure guidance (too vague)
- No examples (model guesses format)
- No priority guidance (misses key details)

---

### flan-t5 Generates Variants (Week 8)

**Variant A** (Structured Format):
```markdown
Analyze the image and rename using this structure:
[main-subject]-[context]-[type].extension

Examples:
- golden-gate-bridge-sunset-photo.jpg
- dashboard-mobile-wireframe-v3.png
- hero-section-desktop-mockup.png

Format: kebab-case, 3-5 words
```

**Variant B** (Color Context):
```markdown
Describe the image as a filename. Include:
1. Main subject/objects
2. Distinctive colors (if notable)
3. Purpose/context

Format: subject-color-context.extension
Max 5 words, kebab-case

Examples:
- blue-button-component-hover.png
- red-alert-modal-mobile.png
```

**Variant C** (Prioritized Metadata):
```markdown
Rename based on visual analysis.

Priority order:
1. Main subject/purpose (required)
2. Platform (mobile/desktop/tablet)
3. Version number (if visible in filename or image)
4. State (hover, active, error, etc.)

Format: subject-platform-version-state.extension
Use kebab-case, omit unavailable fields

Examples:
- login-form-mobile-v2.png
- error-modal-desktop-active.png
- product-card-tablet.png
```

---

### A/B Testing Results (Week 8-9)

```
File: Screenshot-2024-10-28.png (landing page hero section on iPhone)

Variant A output: "hero-section-mobile-landing.png"
Variant B output: "blue-hero-mobile-header.png"
Variant C output: "hero-mobile-landing-v1.png"

User choice: Variant A (clear, no redundant "v1")

---

File: dashboard_FINAL_v3.png

Variant A output: "dashboard-admin-interface-v3.png"
Variant B output: "gray-dashboard-layout.png"
Variant C output: "dashboard-desktop-v3.png"

User choice: Variant C (captured version number!)

---

After 30 votes:
Variant A: 10 votes (33%)
Variant B: 5 votes (17%)
Variant C: 15 votes (50%) â† WINNER

Variant C accuracy: 91% (up from 78%)
```

---

### Promotion (Week 10)

```yaml
# config.yaml - Auto-updated
skills:
  file-naming:
    prompt_template: skills/file-naming-v2.md  # â† New version
    prompt_version: 2
    evolved_at: "2024-11-10T08:00:00Z"
    evolution_history:
      - version: 1
        active_period: "2024-09-15 to 2024-11-10"
        accuracy: 0.78
        reason: "Accuracy drop"
      - version: 2
        active_since: "2024-11-10"
        accuracy: 0.91
        source: "flan-t5 evolution (variant C)"
```

**New prompt file created**:
```bash
skills/file-naming-v2.md  # Variant C promoted
```

**Monitoring continues**: If v2 accuracy drops, trigger evolution again

---

## Implementation Phases

### Phase 1: Manual Prompt Evolution (No flan-t5)

```bash
# User manually creates variants
tinyarms prompt create file-naming \
  --variant-a skills/file-naming-structured.md \
  --variant-b skills/file-naming-colors.md \
  --variant-c skills/file-naming-priority.md

# tinyArms A/B tests (30 votes)
# Winner auto-promoted
```

**Deliverable**: A/B testing framework, winner promotion logic

---

### Phase 2: flan-t5 Auto-Generation

```bash
# Accuracy drops, flan-t5 auto-generates variants
# (No user action needed)
```

**Deliverable**: Integrate flan-t5:small, variant generation logic

---

### Phase 3: Multi-Skill Learning

```yaml
# Learnings from file-naming evolution applied to audio-actions
prompt_evolution:
  cross_skill_learning: true
  # If file-naming improved with "prioritized metadata" structure,
  # apply similar structure to audio-actions prompts
```

**Deliverable**: Meta-learning across skills

---

## Storage Schema

```sql
-- SQLite tables

CREATE TABLE prompt_evolution_sessions (
  id TEXT PRIMARY KEY,
  skill TEXT NOT NULL,
  original_prompt_hash TEXT NOT NULL,
  triggered_at TIMESTAMP NOT NULL,
  trigger_reason TEXT,  -- "accuracy_drop", "manual", "scheduled"
  status TEXT DEFAULT 'active',  -- active, completed, cancelled
  completed_at TIMESTAMP
);

CREATE TABLE prompt_variants (
  id TEXT PRIMARY KEY,
  session_id TEXT REFERENCES prompt_evolution_sessions(id),
  variant_letter TEXT,  -- A, B, C
  prompt_template TEXT NOT NULL,
  reasoning TEXT,  -- Why flan-t5 generated this variant
  votes INTEGER DEFAULT 0,
  accuracy REAL DEFAULT 0.0
);

CREATE TABLE ab_test_results (
  id TEXT PRIMARY KEY,
  session_id TEXT REFERENCES prompt_evolution_sessions(id),
  variant_id TEXT REFERENCES prompt_variants(id),
  task_id TEXT NOT NULL,
  user_choice BOOLEAN,  -- TRUE if user picked this variant
  task_success BOOLEAN,  -- TRUE if task completed successfully
  created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

CREATE TABLE prompt_history (
  id TEXT PRIMARY KEY,
  skill TEXT NOT NULL,
  version INTEGER NOT NULL,
  prompt_template_path TEXT NOT NULL,
  active_from TIMESTAMP NOT NULL,
  active_to TIMESTAMP,
  accuracy_start REAL,
  accuracy_end REAL,
  evolution_source TEXT,  -- "flan-t5", "manual", "initial"
  notes TEXT
);
```

---

## Cost Analysis

**Per evolution cycle**:
- flan-t5 inference: ~2-3s (one-time)
- A/B testing: 30 user choices (spread over 7 days)
- Storage: ~5KB per evolution session

**ROI**:
- Accuracy improvement: 5-15%
- User time saved: 2-3 hours/week (fewer manual prompt tweaks)
- Model swap avoidance: If prompt evolution fixes accuracy, no need to upgrade to larger model

**Break-even**: 1 evolution cycle = worth it if saves >1 hour of manual prompt engineering

---

## Testing Plan

### Phase 1: Manual Testing

1. Create 3 manual variants for file-naming
2. Run A/B test with 30 real files
3. Measure:
   - User choice distribution
   - Accuracy improvement
   - User satisfaction (survey)

**Success criteria**: Winner accuracy >85% (up from 78%)

---

### Phase 2: flan-t5 Testing

1. Use flan-t5 to generate variants (same failure examples)
2. Compare flan-t5 variants vs manual variants
3. Measure:
   - Variant quality (do they make sense?)
   - User choice distribution
   - Accuracy improvement

**Success criteria**: flan-t5 variants perform â‰¥ manual variants

---

### Phase 3: Production Testing

1. Deploy to 1 skill (file-naming)
2. Monitor for 1 month
3. Measure:
   - Number of evolution cycles triggered
   - Average accuracy improvement
   - User annoyance (A/B dialog frequency)

**Success criteria**: 2-3 evolution cycles, accuracy stable >85%, <10% users complain

---

## Risks & Mitigations

### Risk 1: Evolution Fatigue

**Problem**: Users annoyed by frequent A/B choice dialogs

**Mitigation**:
- Cooldown: Max 1 evolution per skill per week
- Sampling: Only 50% of tasks show A/B choice
- Skip button: Always allow using current prompt

---

### Risk 2: flan-t5 Generates Bad Variants

**Problem**: Variants are nonsensical or redundant

**Mitigation**:
- Manual review: Flag for human review if accuracy <70%
- Rollback: Auto-rollback to previous prompt if new prompt performs worse
- Diversity check: Reject variants too similar to original

---

### Risk 3: Overfitting to User

**Problem**: Prompts optimize for one user's preferences, not general use

**Mitigation**:
- Multi-user data: Aggregate votes from multiple users
- Canonical examples: Include gold-standard examples in evaluation
- Periodic reset: Option to reset to default prompt if user wants

---

## References

- **flan-t5 model card**: https://huggingface.co/google/flan-t5-small
- **A/B testing best practices**: Kohavi & Longbotham (2017), "Online Controlled Experiments"
- **Prompt optimization**: OpenAI prompt engineering guide
- **Meta-learning**: Nichol et al. (2018), "Reptile: A Scalable Meta-Learning Algorithm"

---

## Status

**Phase**: Research (0% implemented)
**Next steps**:
1. Validate flan-t5:small can generate coherent prompt variants
2. Build A/B testing UI (terminal prompt or macOS notification)
3. Implement SQLite schema for tracking
4. Test with file-naming skill (high variation, easy to judge)

**Timeline**:
- Phase 1 (Manual): Week 1-2 (build A/B framework)
- Phase 2 (flan-t5): Week 3-4 (integrate model)
- Phase 3 (Production): Week 5+ (deploy to 1-2 skills)

---

**Key insight**: flan-t5 is NOT a per-task overhead. It's a **self-improvement system** that runs in the background when skills need tuning.
