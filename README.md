<p align="center">
  <img src="tinyarms-logo.jpg" alt="tinyArms" width="300" />
</p>

# ü¶ñ tinyArms

**AI assistants that run on your laptop, cost nothing, and get smarter over time.**

Super lightweight. Designed to be invisible. Learns from your preferences. Grows with you. Task-specific. Makes your life easier without sucking you in or replacing your brain like bigger LLMs.

---

## ‚ö†Ô∏è Status: Early Development (~15% Implemented)

**What works**: Core infrastructure (design principles loading, Ollama client, CLI framework, SQLite logging).

**What doesn't**: Tiered routing, file naming, markdown analysis, audio actions, prompt evolution system.

Most documentation describes the **architecture design**, not working features. See "What Works Now" below for actual implementation status.

**Timeline**: Architecture complete (2025-10-27). Core linting infrastructure implemented (2025-10-30). Full feature set in progress.

‚≠ê **Star this repo** to follow development.

---

## ‚úÖ What Works Now (v0.1.0)

**Implemented** (Week 1-2, 2025-10-30):
- ‚úÖ Design principles loading from `~/.tinyarms/principles.md`
- ‚úÖ Ollama model validation (`qwen2.5-coder:3b` availability check)
- ‚úÖ SQLite logging/metrics database
- ‚úÖ CLI framework (`tinyarms lint [file]`)
- ‚ö†Ô∏è Code linting (infrastructure ready, rule detection needs fixing)

**Tests**: 6/10 passing (principles loader, model checker, Ollama client work)

**Not Implemented** (design only):
- ‚ùå Tiered routing (Level 0-3 system)
- ‚ùå File naming skill
- ‚ùå Markdown analysis skill
- ‚ùå Audio actions skill
- ‚ùå Prompt evolution (PromptBreeder + Thompson Sampling)
- ‚ùå MCP server integration
- ‚ùå LaunchAgent automation

---

## The Vision

Imagine you download a screenshot. tinyArms **watches your Downloads folder**, reads the file (OCR if needed), and offers **3 intelligent names**:

```
Screenshot_2025-10-27.png

tinyArms suggests:
  1. hero-section-mobile-v1.png
  2. landing-page-screenshot.png
  3. website-mockup-draft.png

You pick #1 (or type your own, or speak it).

tinyArms learns: "This user prefers structured names with platform + version."

Next screenshot ‚Üí Better suggestions. Every choice trains the system.
```

**This is personalized for YOU.** The prompts evolve with your preferences while keeping you in the driver's seat 100%.

---

## What Makes ü¶ñ tinyArms Different

### 1. Self-Improving via Prompt Evolution

Most AI tools use static prompts. tinyArms will **adaptive prompts** that improve through user feedback:

- **Accuracy drops?** System generates 3 new prompt variants (offline, using SmolLM2-360M or jan-nano-4b)
- **You vote** on which output is best (A/B testing via Thompson Sampling)
- **System learns** and promotes the winning prompt
- **Result**: 78% ‚Üí 89% accuracy improvement over 2 weeks (file-naming benchmark)

**3-tier generation** with intelligent fallback:
- **Tier 1**: SmolLM2-360M (250MB, offline, 60-70% success)
- **Tier 2**: jan-nano-4b (4.3GB, offline, 25-30% cases)
- **Tier 3**: GPT 5 mini (cloud fallback, 5-10% cases, ~$0.004/evolution)

**Cost**: 99% offline, <$0.06/year total.

### 2. Tiered Routing (Fast Rules + Smart AI)

Not everything needs AI. ü¶ñ tinyArms routes tasks intelligently:

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Level 0: Deterministic Rules                               ‚îÇ
‚îÇ  - Hardcoded color check: bg-[#3B82F6]                      ‚îÇ
‚îÇ  - Latency: <1ms                                            ‚îÇ
‚îÇ  - Coverage: 60-75% of tasks                                ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
              ‚Üì (Not matched)
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Level 1: embeddinggemma 300M (Semantic Routing)            ‚îÇ
‚îÇ  - Classify intent via embeddings                           ‚îÇ
‚îÇ  - Latency: <100ms                                          ‚îÇ
‚îÇ  - Coverage: 20-25% of tasks                                ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
              ‚Üì (Complex task)
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Level 2: Qwen2.5-Coder-3B (Code Analysis)                  ‚îÇ
‚îÇ  - Constitutional linting, refactoring suggestions          ‚îÇ
‚îÇ  - Latency: 2-3s                                            ‚îÇ
‚îÇ  - Coverage: 10-15% of tasks                                ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
              ‚Üì (Research needed)
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Level 3: jan-nano-4b (MCP Research Agent)                  ‚îÇ
‚îÇ  - Multi-source synthesis (Context7, GitHub, Filesystem)    ‚îÇ
‚îÇ  - Latency: 8-12s                                           ‚îÇ
‚îÇ  - Coverage: <5% of tasks                                   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Result**: Simple tasks instant, complex tasks wait 2-3s, research 8-12s. Best of both worlds.

### 3. 100% Offline (Privacy-First, Zero Cost)

- **No internet required** - Works on flights, cafes with bad WiFi, strict corporate networks
- **No API keys** - No OpenAI/Anthropic accounts needed
- **No subscriptions** - $0/month vs $20-100/month for Claude/ChatGPT/Copilot
- **Total privacy** - Your code, files, and data never leave your machine
- **Cloud fallback optional** - Tier 3 can use Claude if needed (<10% of tasks, ~$0.01/evolution)

**Models run locally via Ollama**: embeddinggemma (200MB), Qwen2.5-Coder-3B (1.9GB), jan-nano-4b (4.3GB)

### 4. Automation-First (Background Tasks, Not Chat)

tinyArms isn't a chatbot. It's designed for **invisible automation**:

**You won't notice it's running. Just files named correctly, code auto-linted, voice notes structured.**

#### Core Skills

**Skill Creation**: tinyArms adopts the [OpenSkills format](https://github.com/numman/openskills) via skill-creator workflow:

```bash
# Generate new skill structure
python3 .claude/skills/skill-creator/scripts/init_skill.py skill-name --path apps/tinyArms/skills

# Validate SKILL.md format
python3 .claude/skills/skill-creator/scripts/quick_validate.py apps/tinyArms/skills/skill-name
```

**Two-phase approach**: idea.md (planning) ‚Üí SKILL.md (implementation via skill-creator)

**Current skills** (template/design stage):

1. **code-linting** - Pre-commit hook, catches hardcoded colors/magic numbers, 2-3s, 85% accuracy (template generated, needs implementation)
2. **file-naming** - Watches Downloads folder, OCR screenshots, suggests 3 names, learns from choices (planned)
3. **markdown-analysis** - Tracks changes in `.specify/memory/`, summarizes important updates every 2 hours (planned)
4. **audio-actions** - MacWhisper transcription ‚Üí structured action items (e.g., "remind me to..." ‚Üí calendar event) (planned)

#### Example: Pre-Commit Linting

```bash
# You commit code with hardcoded color
git commit -m "Add hero section"

# tinyArms (Level 0 rule, <1ms):
‚ùå hero.tsx:12 - Hardcoded color #3B82F6
   Use semantic token: bg-primary

# You fix it, commit again
‚úÖ All checks passed (2.3s)
```

**Like a T-Rex**: Small arms, but surprisingly capable for automation tasks.

---

## How Prompt Evolution Works (User Journey)

Let's say your file-naming accuracy drops from 92% ‚Üí 78% (you're rejecting more suggestions).

### Week 1: System Detects Drift

```yaml
Drift Detection (ADWIN algorithm):
  - 20 recent tasks: 78% accuracy (below 80% threshold)
  - Trigger: Generate new prompt variants
```

### Week 2: System Generates Variants

```yaml
Tier 1 (SmolLM2-360M, offline):
  - Analyzes 20 failure examples + 10 successes
  - Generates 3 prompt variants (5-8s)
  - Quality gates: Coherence >70/100, diversity >0.90

If variants pass ‚Üí User voting
If variants fail ‚Üí Escalate to Tier 2 (jan-nano-4b, 8-12s)
If Tier 2 fails ‚Üí Escalate to Tier 3 (Claude, cloud, ~$0.01)
```

### Week 3: You Vote (Thompson Sampling A/B Test)

```yaml
Next 20 file-naming tasks, you see variants:

Task 1: Screenshot.png
  Variant A: screenshot-2025.png         (Original)
  Variant B: landing-page-mockup.png     (SmolLM2 variant)
  Variant C: hero-mobile-screenshot.png  (SmolLM2 variant)

You pick C ‚Üí System records vote
```

**Thompson Sampling** dynamically allocates traffic:
- Early on: Equal split (33% each)
- After 10 votes: Variant C winning ‚Üí Gets 60% traffic
- After 20 votes: Variant C wins (15 votes, 91% accuracy) ‚Üí **Promoted**

### Week 4: Winning Prompt Auto-Promoted

```yaml
config.yaml updated:
  file-naming:
    prompt_version: 2
    evolved_at: "2025-11-03T10:00:00Z"
    previous_accuracy: 0.78
    current_accuracy: 0.91  # +13% improvement
```

**You did nothing except pick which outputs you liked. The system learned.**

---

## Hardware Requirements

| RAM  | Models Available | Storage | Performance |
|------|------------------|---------|-------------|
| 8GB  | Level 0-2 (rules + embeddings + Qwen-3B) | 2.1GB | Good (pre-commit linting works) |
| 16GB ‚úÖ | All levels (+ jan-nano-4b research) | 6.4GB | Recommended (full feature set) |
| 32GB | All levels + Qwen-7B (optional deep analysis) | 13.9GB | Best (fastest routing) |

**Platform**: macOS 12.0+ (Apple Silicon recommended). Linux support planned.

---

## Quick Start (When Implemented)

```bash
# Install Ollama
brew install ollama

# Pull core models (2.1GB)
ollama pull embeddinggemma:300m
ollama pull qwen2.5-coder:3b

# Install tinyArms (not available yet - 0% implemented)
npm install -g tinyarms

# Run pre-commit linting
tinyarms run code-linting-fast src/

# Watch Downloads folder for file naming
tinyarms watch ~/Downloads --skill file-naming

# Status overview
tinyarms status
```

---

## Documentation

All documentation is organized by **implementation phase**:

### Phase 0: Foundation (Start Here)
- **[00-OVERVIEW.md](docs/00-OVERVIEW.md)** - What tinyArms is, why it exists, how it works
- **[00-GETTING-STARTED.md](docs/00-GETTING-STARTED.md)** - Prerequisites, first-run setup

### Phase 1: Core Architecture
- **[01-ARCHITECTURE.md](docs/01-ARCHITECTURE.md)** - Tiered routing, skills, MCP integration (original)
- **[01-ARCHITECTURE-V2.md](docs/01-ARCHITECTURE-V2.md)** - Refined architecture with jan-nano-4b
- **[01-MODELS.md](docs/01-MODELS.md)** - All model decisions, benchmarks, rationale

### Phase 2: Configuration & Setup
- **[02-INSTALLATION.md](docs/02-INSTALLATION.md)** - Detailed install steps
- **[02-CONFIGURATION.md](docs/02-CONFIGURATION.md)** - Config examples, YAML structure
- **[02-TROUBLESHOOTING.md](docs/02-TROUBLESHOOTING.md)** - Common issues, solutions
- **[02-constants-audit.md](docs/02-constants-audit.md)** - Audit trail for all numeric constants (latency, coverage, memory)

### Phase 3: Features & Integrations
- **[03-SKILLS.md](docs/03-SKILLS.md)** - What each skill does (linting, file-naming, etc.)
- **[03-INTEGRATIONS.md](docs/03-INTEGRATIONS.md)** - MacWhisper, Claude Code, MCP servers
- **[03-jan-nano-4b-research-agent.md](docs/03-jan-nano-4b-research-agent.md)** - 10 use cases for MCP research agent

### Phase 4: Design Ideations & Research
- **[04-direct-model-access.md](docs/04-direct-model-access.md)** - CLI/MCP for direct model access
- **[04-launchagent-ideations.md](docs/04-launchagent-ideations.md)** - Automation strategies (LaunchAgents, cron)
- **[04-mcp-server-ideations.md](docs/04-mcp-server-ideations.md)** - MCP server integration design
- **[04-swiftui-app-ideations.md](docs/04-swiftui-app-ideations.md)** - GUI mockups (future)
- **[research/04-openskills-integration-decision.md](docs/research/04-openskills-integration-decision.md)** - OpenSkills adoption, execution architecture (Skills ‚Üí Routing ‚Üí Activation)

### Phase 5: Advanced Systems (Prompt Evolution)
- **[05-prompt-evolution-system.md](docs/05-prompt-evolution-system.md)** - Complete overview of self-improving prompts
- **[05-prompt-evolution/](docs/05-prompt-evolution/)** - Detailed research integration:
  - **[01-promptbreeder.md](docs/05-prompt-evolution/01-promptbreeder.md)** - Genetic algorithm for variant generation
  - **[02-thompson-sampling.md](docs/05-prompt-evolution/02-thompson-sampling.md)** - Bayesian A/B testing
  - **[03-llm-as-judge.md](docs/05-prompt-evolution/03-llm-as-judge.md)** - Flow Judge pre-screening
  - **[04-task-specific-patterns.md](docs/05-prompt-evolution/04-task-specific-patterns.md)** - Proven patterns per skill
  - **[05-drift-detection.md](docs/05-prompt-evolution/05-drift-detection.md)** - ADWIN algorithm, multi-signal monitoring
  - **[06-offline-constraints.md](docs/05-prompt-evolution/06-offline-constraints.md)** - 3-tier generation strategy

---

## Technical Highlights (For Researchers)

### Prompt Evolution System

- **PromptBreeder** (Google DeepMind, ICML 2024) for variant generation via genetic algorithms
- **Thompson Sampling** for Bayesian A/B testing with dynamic traffic allocation
- **ADWIN drift detection** for early warning before accuracy drops
- **Multi-signal monitoring** with evidence-based weights: 25% accuracy, 40% user feedback (ground truth dominates)
- **3-tier generation**: SmolLM2-360M ‚Üí jan-nano-4b ‚Üí Claude (99% offline, <$0.10/year)
- **Flow Judge** (3.8B) for pre-screening variants, reduces user burden 33-55%

### Tiered Routing

- **Level 0**: Deterministic rules (regex, AST parsing) for 60-75% coverage, <1ms
- **Level 1**: embeddinggemma-300m for semantic routing, <100ms, 20-25% coverage
- **Level 2**: Qwen2.5-Coder-3B for code analysis, 2-3s, 10-15% coverage
- **Level 3**: jan-nano-4b for MCP research (Context7, GitHub, Filesystem), 8-12s, <5% coverage

### Offline-First Design

- **Ollama** for local model serving (quantized Q4/Q8 models)
- **embeddinggemma** (200MB) for fast semantic search
- **Qwen2.5-Coder** (1.9GB) for code tasks, 80-110 tok/s on M2 Air
- **jan-nano-4b** (4.3GB) for MCP tool-calling research, 83.2% SimpleQA accuracy
- **SmolLM2-360M** (250MB) for prompt generation, 41% IFEval (best-in-class for 360M models)

### Research-Driven

Every architectural decision is backed by:
- 51+ academic papers (PromptBreeder, Thompson Sampling, ADWIN, G-Eval, etc.)
- Benchmark comparisons (IFEval, SimpleQA, HumanEval, GSM8K)
- Production evidence (Google SRE, Healthcare NEWS2, Security SIEM)
- Validation experiments designed before implementation

---

## Why "tinyArms"?

Like a **T-Rex**: Small arms, but surprisingly capable when working WITH larger tools (Claude, GPT, Ollama).

tinyArms doesn't replace your brain or your workflow. It's the **invisible AI assistant** that learns your preferences, handles repetitive tasks, and gets better over time‚Äîwithout you thinking about it.

---

## Call to Action

‚≠ê **Star this repo** to follow development.

**Timeline**:
- ‚úÖ Architecture complete (2025-10-27)
- ‚úÖ OpenSkills skill-creator adoption (2025-10-30)
- ‚úÖ Execution architecture documented (Skills ‚Üí Routing ‚Üí Activation)
- ‚è≠Ô∏è Phase 1 implementation (Q1 2025): Tiered routing + code linting
- ‚è≠Ô∏è Phase 2 implementation (Q2 2025): Prompt evolution system
- ‚è≠Ô∏è Phase 3+ (Q3 2025): Full feature set (file-naming, markdown, audio)

**Next Steps**:

**Phase 1 - First Skill (code-linting)**:
1. Edit SKILL.md (replace TODOs, choose Workflow-Based pattern)
2. Create config.yaml (model config, activation modes, prompts)
3. Create index.ts (export execute + getConfig) + executor.ts (inference logic)
4. Add references/constitution-excerpt.md, validate with quick_validate.py

**Phase 2 - Infrastructure**:
1. Build skill-registry.ts (auto-discover skills/, extract SKILL.md frontmatter)
2. Build cli-handler.ts (map commands to skills, argument parsing)
3. Build routing for ambiguous NL requests (keywords ‚Üí embeddings)

**Phase 3 - Validate with 2nd Skill**:
1. Add file-naming or markdown-analysis skill
2. Test skill-registry auto-discovery
3. Extract duplicated patterns (if 2+ exist)

**Phase 4 - Autonomous Mode**:
1. Build scheduler.ts (read config.yaml, cron + file watchers)
2. Add batching logic (process multiple files per execution)
3. Add semantic caching (Level -1, FrugalGPT pattern)
4. LaunchAgent integration (macOS native scheduling)

**Contributors welcome** once implementation starts. Perfect time to explore the architecture and prepare.

---

## License

MIT ü¶ñ

**Research-driven. Offline-first. Learns from YOU.**
