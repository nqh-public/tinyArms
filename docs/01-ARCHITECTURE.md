# 01 - Architecture

**High-level overview of tinyArms architecture**

For detailed implementation, model decisions, configuration, and integrations, see the specialized docs linked below.

---

## System Overview

```
Activation Modes (Entry Points)
‚îú‚îÄ CLI Handler (tinyarms lint file.ts) ‚Üí Direct skill invocation
‚îú‚îÄ Scheduler (cron/file watchers) ‚Üí Automated skill execution
‚îú‚îÄ GUI Handler (SwiftUI, future) ‚Üí User-selected skill
‚îî‚îÄ Ambiguous Requests ‚Üí Routing layer (optional)
          ‚Üì
    Routing Layer (Optional - Ambiguous Requests Only)
‚îú‚îÄ skill-registry.ts (auto-discovers skills/)
‚îú‚îÄ Extracts SKILL.md frontmatter (name + description)
‚îú‚îÄ Hybrid routing: Keywords ‚Üí embeddings
‚îî‚îÄ embeddinggemma:300m for semantic matching
          ‚Üì
    Skills Layer (Self-Contained Execution Units)
‚îú‚îÄ code-linting/ (SKILL.md + config.yaml + index.ts + executor.ts)
‚îú‚îÄ file-naming/ (same structure)
‚îú‚îÄ markdown-analysis/ (same structure)
‚îî‚îÄ audio-actions/ (same structure)
          ‚Üì
    Tiered Routing (Per Skill, Configured in config.yaml)
‚îú‚îÄ Level -1: Semantic Cache (Phase 03, researched, 15-25% elimination)
‚îÇ  ‚îî‚îÄ Vector similarity >0.95 ‚Üí return cached (<50ms)
‚îú‚îÄ Level 0: Deterministic rules (<1ms, 60-75% of tasks)
‚îÇ  ‚îî‚îÄ Keyword extraction, file type detection, kebab-case formatting
‚îú‚îÄ Level 1: embeddinggemma 300M (<100ms, 20-25% of tasks)
‚îÇ  ‚îî‚îÄ Semantic routing, intent classification (200MB)
‚îú‚îÄ Level 2: Small specialists (2-4s, 10-15% of tasks)
‚îÇ  ‚îú‚îÄ Primary: Qwen2.5-Coder-3B-Instruct (1.9GB, code linting)
‚îÇ  ‚îú‚îÄ Answer Consistency Scoring (Phase 02, researched)
‚îÇ  ‚îÇ  ‚îî‚îÄ Generate N=3, similarity >0.85 ‚Üí accept, <0.85 ‚Üí escalate
‚îÇ  ‚îú‚îÄ Secondary: Qwen3-4B-Instruct (2.5GB, general tasks, optional)
‚îÇ  ‚îî‚îÄ Optional: Gemma 3 4B (2.3GB, file naming/markdown, reused from Cotypist)
‚îú‚îÄ Level 3: Deep analysis (10-15s, optional, <5% of tasks)
‚îÇ  ‚îî‚îÄ Qwen2.5-Coder 7B (4.7GB, architectural violations, weekly scans)
‚îî‚îÄ Industry Validation: 90% aligned (FrugalGPT, RouteLLM, GitHub Copilot patterns)
          ‚Üì
    Storage
‚îú‚îÄ SQLite (task history, metrics, feedback)
‚îî‚îÄ Config (YAML per skill + global settings)
          ‚Üì
    Models (Ollama)
‚îú‚îÄ embeddinggemma:300m (200MB, semantic routing)
‚îú‚îÄ Qwen2.5-Coder-3B-Instruct (1.9GB, primary Level 2 for code)
‚îú‚îÄ Qwen3-4B-Instruct (2.5GB, secondary Level 2 for general tasks, optional)
‚îú‚îÄ Gemma 3 4B (2.3GB, optional Level 2, reused from Cotypist)
‚îî‚îÄ Qwen2.5-Coder 7B (4.7GB, optional Level 3 for deep analysis)
```

---

## Tiered Routing System

### Philosophy

**Use the smallest/fastest model that meets accuracy requirements.**

60-75% of tasks should be handled by Level 0 (rules, no models). Only escalate to AI when truly necessary!

---

### Level -1: Semantic Cache

**Purpose**: Return cached answers for similar queries (<50ms)
**Status**: Researched (Phase 03)
**Expected Impact**: 15-25% query elimination

**How it works**:
- Embed incoming query (reuse embeddinggemma from Level 1)
- Search vector DB for similar cached queries
- Similarity >0.95 ‚Üí Return cached response (~60ms)
- Similarity ‚â§0.95 ‚Üí Continue to Level 0

**Performance**:
- Cache hit: ~60ms (40x faster than Level 2)
- Cache miss overhead: +50ms (minimal impact on 2-3s total)
- Memory: 500-800MB for 100K cached entries

**Full details**: See [research/03-semantic-caching-design.md](research/03-semantic-caching-design.md)

---

### Level 0: Deterministic Rules

**Purpose**: Instant responses for pattern-matching tasks (<1ms)
**Target**: Handle 60-75% of tasks here
**Status**: ‚ö†Ô∏è Coverage % assumed (needs validation)

**Examples**:
- Filename formatting (kebab-case)
- Keyword extraction (RAKE algorithm)
- File type detection (extension + path)
- Directory mapping (lookup tables)

**Characteristics**:
- Speed: <1ms
- Accuracy: 100% (when rules match)
- Size: 0 bytes
- Research range: 10-40% in production systems (Semantic Router, Intercom)

**Full details**: See [03-INTEGRATIONS.md - Rules Engine section]

---

### Level 1: Tiny Embeddings

**Purpose**: Semantic understanding layer for routing (NOT generative)
**Model**: embeddinggemma:300m (200MB)
**Speed**: <15ms per embedding on M2
**Target**: Handle 20-25% of tasks here

**Use Cases**:
- File type classification
- Intent extraction from voice
- Constitutional principle similarity search

**Characteristics**:
- Speed: <100ms
- Accuracy: 85-90% (classification) ‚ö†Ô∏è ASSUMED
- Output: 768-dimensional vectors

**Full details**: See [01-MODELS.md - Level 1 section](01-MODELS.md#level-1-embeddinggemma300m--decided)

---

### Level 2: Small Generalists

**Purpose**: Complex reasoning and generation
**Primary**: Qwen2.5-Coder-3B-Instruct (1.9GB, code linting)
**Speed**: 2-3s per file ‚ö†Ô∏è NEEDS M2 AIR TESTING
**Target**: Handle 10-15% of tasks here

**What it detects**:
- Hardcoded colors, magic numbers
- File size violations (>350 LOC)
- Import alias violations
- Missing line references
- Simple DRY violations

**Accuracy**: 85% (15% miss rate on complex violations) ‚ö†Ô∏è ASSUMED

**Optional specialists**:
- Qwen3-4B-Instruct (2.5GB) - General instruction-following tasks
- Gemma 3 4B (2.3GB) - File naming, markdown, audio (reused from Cotypist)

**Full details**: See [01-MODELS.md - Level 2 section](01-MODELS.md#level-2-primary-qwen25-coder-3b-instruct--decided)

---

### Level 3: Code Specialists

**Purpose**: Deep architectural analysis (optional)
**Model**: Qwen2.5-Coder 7B (4.7GB)
**Speed**: 10-15s per file ‚ö†Ô∏è NEEDS M2 AIR TESTING
**Target**: Handle <5% of tasks here

**What it catches (vs Level 2)**:
- Architectural anti-patterns (God objects, circular deps)
- Complex DRY violations (semantic duplication)
- Cross-file pattern analysis
- Component decomposition issues

**Accuracy**: 95% (vs 85% for Level 2) ‚ö†Ô∏è ASSUMED

**When to install**:
- Level 2 misses >10% violations
- Need architectural enforcement
- Want weekly deep scans (not pre-commit blocking)

**Full details**: See [01-MODELS.md - Level 3 section](01-MODELS.md#level-3-qwen25-coder-7b--optional)

## Confidence Scoring

**Status**: Researched (Phase 02)
**Expected Impact**: 20-30% reduction in Level 3 escalations
**Implementation**: Week 3

**Problem**: Level 2 doesn't know when its answer is good enough vs when to escalate to Level 3

**Solution**: Answer Consistency Scoring
- Generate N=3 responses with temperature=0.7
- Measure semantic similarity between all 3
- Threshold: >0.85 ‚Üí accept Level 2, <0.85 ‚Üí escalate to Level 3

**Why this works**: LLMs produce consistent answers when confident, inconsistent when uncertain

**Trade-offs**:
- Latency: +500ms at Level 2
- Accuracy: Prevents false confidence
- Cost: 20-30% fewer expensive Level 3 calls

**Industry validation**: AutoMix (NeurIPS 2024) achieves 50%+ cost reduction via self-verification

**Full details**: See [research/02-confidence-scoring-patterns.md](research/02-confidence-scoring-patterns.md)

---

## Token Budget Enforcement Strategy

**Status**: Utilities implemented (2025-10-30), enforcement points documented (2025-11-01)
**Implementation**: src/utils/token-counter.ts:1-66 (ready), integration pending

### Overview

Token budgets prevent context overflow and ensure predictable performance. Based on Anthropic's "Writing Tools for Agents" (2025-11-01), all responses MUST enforce maximum token limits.

**Reference**: https://www.anthropic.com/engineering/writing-tools-for-agents

### Budget Limits

| Response Format | Target Tokens | Max Tokens | Use Case |
|----------------|---------------|------------|----------|
| **concise** | 5,000 | 25,000 | CLI quick checks, pre-commit hooks |
| **detailed** | 15,000 | 25,000 | MCP tools, interactive debugging |
| **streaming** | N/A | 25,000 | Long operations (batch linting) |

**Hard Limit**: 25,000 tokens (Claude Code standard, enforced via truncation)

### Enforcement Points

#### 1. Linter (Level 2 AI)
**File**: src/linting/linter.ts:52-60
**Status**: ‚úÖ Implemented

```typescript
// Truncate if budget exceeded
if (estimatedTokens > tokenLimits.MAX) {
  result.violations = truncateViolations(result.violations, format, tokenLimits)
}
```

**Behavior**:
- Concise: Return first 10 violations + summary
- Detailed: Return first 20 violations with full context
- Always include metadata: `truncated: true, total_violations: 47`

#### 2. MCP Tools
**File**: src/mcp/types.ts:118-123
**Status**: ‚ö†Ô∏è Defined, not enforced

```typescript
export const TOKEN_LIMITS = {
  MAX_RESPONSE: 25000,
  CONCISE_TARGET: 5000,
  DETAILED_TARGET: 15000
}
```

**Integration Needed**: Apply `truncateResponse()` in review-code.ts, organize-files.ts, research-context.ts (when router connects)

#### 3. Tiered Router (Future)
**File**: src/router/tiered-router.ts (not implemented)
**Status**: ‚ùå Design only

**Expected Logic**:
```typescript
async route(input: Input, format: ResponseFormat) {
  const result = await levelN.execute(input)

  if (countTokens(result) > TOKEN_LIMITS.MAX_RESPONSE) {
    return truncateResponse(result, format)
  }

  return { ...result, metadata: { tokens: countTokens(result) } }
}
```

#### 4. Skill Registry (This Implementation)
**File**: src/skills/registry.ts (in progress)
**Status**: üîÑ Building now

**Metadata Tracking**:
```typescript
interface SkillMetadata {
  token_budget: number  // Per-skill limit (5k-25k)
  // Used by CLI/MCP to enforce budgets BEFORE execution
}
```

**Example**:
- `code-linting-fast`: 15,000 tokens (detailed violations)
- `file-naming`: 5,000 tokens (concise suggestions)
- `markdown-analysis`: 10,000 tokens (change summaries)

### Truncation Strategy

**Utility**: src/utils/token-counter.ts:33-65

**Rules**:
1. **Preserve metadata** (latency, level, total count)
2. **Slice arrays** (violations, suggestions, files)
3. **Add truncation notice** (`truncated: true, showing: 10, total: 47`)
4. **Maintain JSON structure** (no broken objects)

**Example Output**:
```json
{
  "violations": [ /* First 10 only */ ],
  "metadata": {
    "truncated": true,
    "showing": 10,
    "total": 47,
    "tokens": 25000
  }
}
```

### Industry Validation

- **Claude Code**: 25k token limit per tool response (Anthropic standard)
- **FrugalGPT**: Token budgets reduce costs 98% (LLM Cascade paper)
- **AutoMix**: Self-verification with token limits prevents waste

### Testing Requirements

**Unit Tests** (src/utils/token-counter.test.ts):
- ‚úÖ countTokens() accuracy within 5%
- ‚úÖ truncateViolations() preserves metadata
- ‚úÖ Token limits enforced (concise: 5k, detailed: 15k, max: 25k)

**Integration Tests** (when router exists):
- [ ] Level 2 response truncated at 25k
- [ ] MCP tools enforce skill-specific budgets
- [ ] CLI shows truncation warnings

---

## Skills Layer

**Status**: Architecture defined (2025-10-30)
**Implementation**: Phase 1 in progress (code-linting)

### Overview

Skills are self-contained execution units. Each skill:
- Defines WHAT it does (SKILL.md - OpenSkills format)
- Configures HOW it runs (config.yaml - runtime settings)
- Implements core logic (executor.ts - model inference)
- Exports standard interface (index.ts - execute + getConfig)

### Structure (Per Skill)

```
skills/{name}/
‚îú‚îÄ‚îÄ SKILL.md           # OpenSkills format (for agents)
‚îú‚îÄ‚îÄ config.yaml        # Runtime config (model, activation, schedule)
‚îú‚îÄ‚îÄ index.ts           # Exports execute() + getConfig()
‚îú‚îÄ‚îÄ executor.ts        # Core logic (model loading, inference)
‚îú‚îÄ‚îÄ scripts/           # Optional: Helper scripts
‚îú‚îÄ‚îÄ references/        # Optional: Docs for context
‚îî‚îÄ‚îÄ assets/            # Optional: Templates
```

### Interface (Flexible Per Skill)

‚ö†Ô∏è **Design Spec** (Not Implemented): Interface signatures below are proposed. Exact implementation TBD during Phase 1.

Each skill exports:
```typescript
export async function execute(input: any): Promise<any>
export function getConfig(): SkillConfig
```

**Note**: Input/output schemas are skill-specific (not standardized)

### SKILL.md Frontmatter = Routing Triggers

**No duplication**: config.yaml does NOT include triggers

**skill-registry extracts**:
```markdown
---
name: code-linting
description: Lint code against constitutional principles using Qwen2.5-Coder-3B
---
```

**Used for**:
- Direct lookup: CLI maps "lint" ‚Üí "code-linting"
- Semantic routing: Ambiguous requests match via description

### config.yaml Schema (Design Spec - Not Implemented)

| Section | Purpose |
|---------|---------|
| `model` | Tiered routing config (level, primary, fallback, threshold) |
| `activation` | Which modes enabled (cli, automated, gui) |
| `schedule` | Automated execution (cron, watch_patterns, batch_size) |
| `performance` | Resource limits (latency, memory, battery) |
| `prompts` | System/user templates |

‚ö†Ô∏è **Status**: Architecture design only. Exact field names, structure, and validation rules TBD during Phase 1 implementation.

**Full schema**: See [research/04-openskills-integration-decision.md](research/04-openskills-integration-decision.md)

---

## Activation Modes

**Status**: Architecture defined (2025-10-30)
**Implementation**: Phase 2 (infrastructure)

### When Routing is Needed

**Direct invocation (NO routing)**:
- ‚úÖ CLI: `tinyarms lint file.ts` ‚Üí Knows skill = code-linting
- ‚úÖ Scheduler: Reads config.yaml ‚Üí Knows which skill
- ‚úÖ GUI: User selects from menu ‚Üí Knows which skill

**Ambiguous requests (routing needed)**:
- ‚ùå "help me with this file" ‚Üí skill-registry routes via embeddings

### 1. CLI Handler (`src/activation/cli-handler.ts`)

‚ö†Ô∏è **Design Flow** (Not Implemented): Flow below shows intended architecture. Actual implementation TBD.

**Flow**:
```
tinyarms lint file.ts
  ‚Üì
Parse: command="lint", args={file}
  ‚Üì
Map: "lint" ‚Üí "code-linting"
  ‚Üì
Load: skills/code-linting/index.ts
  ‚Üì
Execute: execute({file})
```

**No routing** - Direct command mapping

### 2. Scheduler (`src/core/scheduler.ts`)

‚ö†Ô∏è **Design Flow** (Not Implemented): Flow below shows intended architecture. Actual implementation TBD.

**Flow**:
```
On startup: Read all config.yaml
  ‚Üì
Find: activation.automated = true
  ‚Üì
Schedule: cron OR file watchers
  ‚Üì
On trigger: Execute skill directly
  ‚Üì
Log to SQLite
```

**No routing** - Config specifies skill

### 3. GUI Handler (`src/activation/gui-handler.ts`)

**Status**: Future (SwiftUI menu bar)

**Flow**:
```
User clicks menu ‚Üí Selects skill ‚Üí Execute directly
```

**No routing** - User chooses skill

### 4. Ambiguous Request Handler

‚ö†Ô∏è **Design Flow** (Not Implemented): Flow below shows intended architecture. Actual implementation TBD.

**Flow**:
```
Input: "help me with this file"
  ‚Üì
skill-registry.route(input)
  ‚Üì
Extract all SKILL.md descriptions
  ‚Üì
embeddinggemma: Semantic match
  ‚Üì
Return: Best matching skill name
  ‚Üì
Load + execute skill
```

**Uses routing** - Doesn't know skill upfront

---

## Industry Validation

**90% aligned** with industry best practices (FrugalGPT, RouteLLM, GitHub Copilot).

**See research/01-industry-validation.md for complete analysis** (25+ papers, 8 projects, 6 case studies)

## Skills (Implementation Status)

| Skill | Status | Model | Use Case |
|-------|--------|-------|----------|
| code-linting | Phase 1 (SKILL.md generated) | Qwen2.5-Coder-3B | Pre-commit hooks |
| file-naming | Planned (Phase 3) | Gemma 3 4B | Batch rename |
| markdown-analysis | Planned (Phase 3) | Gemma 3 4B | Track .specify/ |
| audio-actions | Planned (Phase 3) | Gemma 3 4B | Voice ‚Üí actions |

**Architecture details**: See [research/04-openskills-integration-decision.md](research/04-openskills-integration-decision.md)
**Skill configuration**: See [03-SKILLS.md](03-SKILLS.md)

## Next Steps

**For detailed information**:
1. **Models**: See [01-MODELS.md](01-MODELS.md) - Model decisions, benchmarks, performance
2. **Configuration**: See [02-CONFIGURATION.md](02-CONFIGURATION.md) - Setup, storage, config system
3. **Integrations**: See [03-INTEGRATIONS.md](03-INTEGRATIONS.md) - MCP, LaunchAgent, MacWhisper, SwiftUI
4. **Skills**: See [03-SKILLS.md](03-SKILLS.md) - Detailed skill configuration and usage
5. **Research**: See [research/*.md](research/) - Industry validation, implementation patterns

---

**Note**: This is a reference implementation (0% executable code). Architecture shown is for design illustration, not actual execution.
